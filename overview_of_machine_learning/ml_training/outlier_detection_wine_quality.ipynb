{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Outlier Detection Techniques and Their Impact on RandomForestRegressor Performance\n", "This notebook compares the effect of different outlier detection techniques on a RandomForestRegressor model using the Wine Quality dataset."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import pandas as pd\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.preprocessing import StandardScaler\n", "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n", "from sklearn.ensemble import IsolationForest, RandomForestRegressor\n", "from scipy.stats import zscore\n", "from scipy.stats.mstats import winsorize\n", "from sklearn.datasets import fetch_openml"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Load the red wine dataset\n", "wine = fetch_openml(name=\"wine-quality-red\", version=1, as_frame=True)\n", "X = wine.data\n", "y = wine.target.astype(int)\n", "\n", "# Convert wine quality to 3 classes: 0 = low, 1 = medium, 2 = high\n", "y = pd.cut(y, bins=[0, 4, 6, 8], labels=[0, 1, 2])\n", "y = y.astype(int)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Train-test split before outlier removal\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n", "column = \"residual_sugar\"  # Column to detect outliers from"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Function to train and evaluate RandomForestRegressor\n", "def evaluate_model(X_train, X_test, y_train, y_test):\n", "    scaler = StandardScaler()\n", "    X_train_scaled = scaler.fit_transform(X_train)\n", "    X_test_scaled = scaler.transform(X_test)\n", "\n", "    model = RandomForestRegressor(n_estimators=500, max_depth=None, max_features='log2', random_state=42)\n", "    model.fit(X_train_scaled, y_train)\n", "    y_pred = model.predict(X_test_scaled)\n", "\n", "    return {\n", "        \"MAE\": mean_absolute_error(y_test, y_pred),\n", "        \"MSE\": mean_squared_error(y_test, y_pred),\n", "        \"R2\": r2_score(y_test, y_pred)\n", "    }"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 1. Original data\n", "original_metrics = evaluate_model(X_train, X_test, y_train, y_test)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 2. Remove 5% extreme values\n", "lower_quantile = X_train[column].quantile(0.05)\n", "upper_quantile = X_train[column].quantile(0.95)\n", "X_train_filtered = X_train[(X_train[column] >= lower_quantile) & (X_train[column] <= upper_quantile)]\n", "y_train_filtered = y_train[X_train_filtered.index]\n", "filtered_metrics = evaluate_model(X_train_filtered, X_test, y_train_filtered, y_test)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 3. Remove outliers using IQR\n", "Q1 = X_train[column].quantile(0.25)\n", "Q3 = X_train[column].quantile(0.75)\n", "IQR = Q3 - Q1\n", "lower_bound = Q1 - 1.5 * IQR\n", "upper_bound = Q3 + 1.5 * IQR\n", "X_train_iqr = X_train[(X_train[column] >= lower_bound) & (X_train[column] <= upper_bound)]\n", "y_train_iqr = y_train[X_train_iqr.index]\n", "iqr_metrics = evaluate_model(X_train_iqr, X_test, y_train_iqr, y_test)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 4. Remove outliers using Z-score\n", "z_scores = zscore(X_train[column])\n", "X_train_zscore = X_train[np.abs(z_scores) <= 3]\n", "y_train_zscore = y_train[X_train_zscore.index]\n", "zscore_metrics = evaluate_model(X_train_zscore, X_test, y_train_zscore, y_test)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 5. Remove outliers using Isolation Forest\n", "iso = IsolationForest(contamination=0.05, random_state=42)\n", "outlier_preds = iso.fit_predict(X_train[[column]])\n", "X_train_iso = X_train[outlier_preds != -1]\n", "y_train_iso = y_train[X_train_iso.index]\n", "iso_metrics = evaluate_model(X_train_iso, X_test, y_train_iso, y_test)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 6. Winsorization\n", "X_train_winsorized = X_train.copy()\n", "X_train_winsorized[column] = winsorize(X_train_winsorized[column], limits=[0.05, 0.05])\n", "winsorized_metrics = evaluate_model(X_train_winsorized, X_test, y_train, y_test)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Create a comparison DataFrame\n", "metrics_df = pd.DataFrame({\n", "    \"Method\": [\"Original\", \"5% Trimmed\", \"IQR\", \"Z-score\", \"Isolation Forest\", \"Winsorized\"],\n", "    \"MAE\": [original_metrics[\"MAE\"], filtered_metrics[\"MAE\"], iqr_metrics[\"MAE\"], zscore_metrics[\"MAE\"], iso_metrics[\"MAE\"], winsorized_metrics[\"MAE\"]],\n", "    \"MSE\": [original_metrics[\"MSE\"], filtered_metrics[\"MSE\"], iqr_metrics[\"MSE\"], zscore_metrics[\"MSE\"], iso_metrics[\"MSE\"], winsorized_metrics[\"MSE\"]],\n", "    \"R2\": [original_metrics[\"R2\"], filtered_metrics[\"R2\"], iqr_metrics[\"R2\"], zscore_metrics[\"R2\"], iso_metrics[\"R2\"], winsorized_metrics[\"R2\"]]\n", "})\n", "metrics_df"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.8"}}, "nbformat": 4, "nbformat_minor": 5}